{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "838846fd-b6ec-4136-93a6-7f57b40461c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\envs\\sql_expert\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, set_seed\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15a8cfcf-638a-476b-8dd8-9a141c397fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "login(os.getenv(\"HF_TOKEN_WRITE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d2c678-499f-4b8c-b856-41c074e3ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# Model\n",
    "BASE_MODEL = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "# Project\n",
    "HF_USER = \"Yihim\"\n",
    "PROJECT_NAME = \"sql_expert\"\n",
    "RUN_NAME = f\"{datetime.now():%Y-%m-%d_%H.%M.%S}\"\n",
    "PROJECT_RUN_NAME = f\"{PROJECT_NAME}--{RUN_NAME}\"\n",
    "\n",
    "# LoRA\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = 32\n",
    "TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    "LORA_DROPOUT = 0.1\n",
    "\n",
    "# Training\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 1\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "LR_SCHEDULER_TYPE = \"cosine\"\n",
    "WARMUP_RATIO = 0.03\n",
    "OPTIMIZER = \"paged_adamw_32bit\"\n",
    "LOG_STEPS = 50\n",
    "SAVE_STEPS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb4027aa-6328-4f64-8e3a-b9cb5156dc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dataset = load_dataset(\"gretelai/synthetic_text_to_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e37a66d8-9b10-4edf-9c04-bb0f6c4fee91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'domain', 'domain_description', 'sql_complexity', 'sql_complexity_description', 'sql_task_type', 'sql_task_type_description', 'sql_prompt', 'sql_context', 'sql', 'sql_explanation'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'domain', 'domain_description', 'sql_complexity', 'sql_complexity_description', 'sql_task_type', 'sql_task_type_description', 'sql_prompt', 'sql_context', 'sql', 'sql_explanation'],\n",
       "        num_rows: 5851\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdeee9ac-dc4a-4f59-8d43-2b43d4722a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sql_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cd34323-f50a-42c8-9eca-a26d2c8791bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.95 * len(sql_dataset[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b29b52-486c-45ad-9432-64852913b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(sql_dataset[\"train\"]))\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274f4bca-42b3-41c6-9b26-13b84f7edb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sql_dataset[\"train\"].select(train_indices)\n",
    "val = sql_dataset[\"train\"].select(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7df9eabe-46fc-40fb-944c-b74fb7796a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: yihimchan (yihimchan-personal) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\PC\\Documents\\self_learning\\0_projects\\sql_expert\\notebooks\\wandb\\run-20250307_144435-xpswe542</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yihimchan-personal/sql_expert/runs/xpswe542' target=\"_blank\">2025-03-07_14.44.27</a></strong> to <a href='https://wandb.ai/yihimchan-personal/sql_expert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yihimchan-personal/sql_expert' target=\"_blank\">https://wandb.ai/yihimchan-personal/sql_expert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yihimchan-personal/sql_expert/runs/xpswe542' target=\"_blank\">https://wandb.ai/yihimchan-personal/sql_expert/runs/xpswe542</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/yihimchan-personal/sql_expert/runs/xpswe542?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x28194a9c3a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=PROJECT_NAME, name=RUN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d6fefb-d813-4ee5-b786-99080693d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_4bit_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a818c9d4-bfa9-461c-a523-6df7e91cd1bf",
   "metadata": {},
   "source": [
    "- install [flash attention 2](https://github.com/kingbri1/flash-attention/releases) that suits your environment\n",
    "- then pip install the wheel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "942147cb-8b2b-49d0-b5c5-cd3b6625b8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 4/4 [00:20<00:00,  5.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint: 5.44 GB\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, \n",
    "                                                  quantization_config=quant_4bit_config,\n",
    "                                                  attn_implementation='flash_attention_2',\n",
    "                                                  device_map=\"auto\",\n",
    "                                                  torch_dtype=torch.bfloat16)\n",
    "base_model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "print(f\"Memory footprint: {base_model.get_memory_footprint() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f715f6d1-fd6d-405c-be00-799d022f5207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(152064, 3584)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
       "          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26eea4bb-dcd5-4d76-9f86-3639aa3c9e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a specialized SQL query generator that helps users write efficient SQL queries. Your role is to analyze the database schema provided in the `sql_context` and generate the appropriate SQL code that answers the user's question in `sql_prompt`.\n",
    "\n",
    "## Input Format\n",
    "\n",
    "You will receive two key inputs:\n",
    "1. `sql_context`: A description of the database schema including CREATE TABLE statements, sample INSERT statements, and any relevant constraints or relationships\n",
    "2. `sql_prompt`: A natural language query from the user describing what data they want to retrieve or what operation they want to perform\n",
    "\n",
    "## Output Rules\n",
    "\n",
    "1. Respond ONLY with the SQL query code - no explanations, comments, or other text\n",
    "2. Generate standard SQL that would work in most SQL databases\n",
    "3. Ensure your query addresses all requirements specified in the user's `sql_prompt`\n",
    "4. Use appropriate JOINs, WHERE clauses, GROUP BY, and aggregate functions as needed\n",
    "5. Write efficient queries that follow SQL best practices\n",
    "6. Do not include any metadata, markdown formatting, or code block indicators in your response\n",
    "7. If the user's request is ambiguous, make reasonable assumptions based on the database schema\n",
    "\n",
    "## Example\n",
    "\n",
    "**sql_context:** CREATE TABLE salesperson (salesperson_id INT, name TEXT, region TEXT); INSERT INTO salesperson (salesperson_id, name, region) VALUES (1, 'John Doe', 'North'), (2, 'Jane Smith', 'South'); CREATE TABLE timber_sales (sales_id INT, salesperson_id INT, volume REAL, sale_date DATE); INSERT INTO timber_sales (sales_id, salesperson_id, volume, sale_date) VALUES (1, 1, 120, '2021-01-01'), (2, 1, 150, '2021-02-01'), (3, 2, 180, '2021-01-01');\n",
    "\n",
    "**sql_prompt:** \"What is the total volume of timber sold by each salesperson, sorted by salesperson?\"\n",
    "\n",
    "**Your response should be exactly:**\n",
    "SQL: SELECT salesperson_id, name, SUM(volume) as total_volume FROM timber_sales JOIN salesperson ON timber_sales.salesperson_id = salesperson.salesperson_id GROUP BY salesperson_id, name ORDER BY total_volume DESC;\n",
    "Explanation: Joins timber_sales and salesperson tables, groups sales by salesperson, calculates total volume sold by each salesperson, and orders the results by total volume in descending order.\n",
    "\n",
    "## Error Handling\n",
    "\n",
    "If the `sql_prompt` requests information that cannot be derived from the provided `sql_context`, generate a query that comes as close as possible to answering the user's intent while only using the tables and columns defined in the `sql_context`.\n",
    "\n",
    "Remember, your only job is to output SQL code that solves the user's query. Do not provide explanations, alternatives, or engage in dialogue.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfd40b96-c932-488a-832b-17dedf8790fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = \"\"\"\n",
    "sql_context:\n",
    "{sql_context}\n",
    "\n",
    "sql_prompt:\n",
    "{sql_prompt}\n",
    "\n",
    "Begin.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a2b0142-5429-4b57-ae3d-9b0da07ece75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSISTANT_PROMPT = \"\"\"\n",
    "SQL: {sql}\n",
    "\n",
    "Explanation: {sql_explanation}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d24c5f19-655b-43d5-8301-f4732ba9fd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████| 95000/95000 [00:14<00:00, 6734.44 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████| 5000/5000 [00:00<00:00, 6064.78 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def format_example(example):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT.format(\n",
    "            sql_context=example[\"sql_context\"], \n",
    "            sql_prompt=example[\"sql_prompt\"])\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\": ASSISTANT_PROMPT.format(\n",
    "            sql=example[\"sql\"], \n",
    "            sql_explanation=example[\"sql_explanation\"])\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return {\"messages\": messages}\n",
    "\n",
    "# Transform the datasets using map\n",
    "formatted_train = train.map(format_example)\n",
    "formatted_val = val.map(format_example)\n",
    "formatted_test = test.map(format_example)\n",
    "\n",
    "# If you need the JSONL format specifically\n",
    "def save_dataset_as_jsonl(dataset, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for item in dataset:\n",
    "            f.write(json.dumps({\"messages\": item[\"messages\"]}) + '\\n')\n",
    "            \n",
    "# Save to files if needed\n",
    "save_dataset_as_jsonl(formatted_train, \"train.jsonl\")\n",
    "save_dataset_as_jsonl(formatted_val, \"val.jsonl\")\n",
    "save_dataset_as_jsonl(formatted_test, \"test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09308a3f-03bd-4aca-9c29-90900b44d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_parameters = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=TARGET_MODULES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9680b402-ae9e-4b84-9bc8-5837183c2e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parametes = SFTConfig(\n",
    "    output_dir=PROJECT_RUN_NAME,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=1,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    optim=OPTIMIZER,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=LOG_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=RUN_NAME,\n",
    "    max_seq_length=2048,\n",
    "    save_strategy=\"steps\",\n",
    "    hub_strategy=\"end\", # \"every_save\"\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=f\"{HF_USER}/qwen2.5-7b-instruct-text-to-sql-v1\",\n",
    "    hub_private_repo=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c6da2b6-7251-45a6-b58a-ebfd17c5ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 95000 examples [00:00, 158805.75 examples/s]\n",
      "Generating train split: 5000 examples [00:00, 181538.59 examples/s]\n",
      "Generating train split: 5851 examples [00:00, 147328.92 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainset = load_dataset(\"json\", data_files=\"train.jsonl\", split=\"train\")\n",
    "valset = load_dataset(\"json\", data_files=\"val.jsonl\", split=\"train\")\n",
    "testset = load_dataset(\"json\", data_files=\"test.jsonl\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3865d852-3759-46ea-912e-ef0fd94328bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_112384\\2089143717.py:1: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  fine_tuning = SFTTrainer(\n",
      "Converting train dataset to ChatML: 100%|██████████████████████████████| 95000/95000 [00:04<00:00, 23588.81 examples/s]\n",
      "Applying chat template to train dataset: 100%|█████████████████████████| 95000/95000 [00:08<00:00, 11070.37 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████████████████████████████████████| 95000/95000 [02:01<00:00, 779.24 examples/s]\n",
      "Truncating train dataset: 100%|█████████████████████████████████████████| 95000/95000 [00:52<00:00, 1794.49 examples/s]\n",
      "Converting eval dataset to ChatML: 100%|█████████████████████████████████| 5000/5000 [00:00<00:00, 24950.80 examples/s]\n",
      "Applying chat template to eval dataset: 100%|████████████████████████████| 5000/5000 [00:00<00:00, 11183.22 examples/s]\n",
      "Tokenizing eval dataset: 100%|█████████████████████████████████████████████| 5000/5000 [00:06<00:00, 775.96 examples/s]\n",
      "Truncating eval dataset: 100%|████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1679.81 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "fine_tuning = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=trainset,\n",
    "    eval_dataset=valset,\n",
    "    peft_config=lora_parameters,\n",
    "    tokenizer=tokenizer,\n",
    "    args=train_parametes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc04bd3-b3ff-4720-9263-5eb03aec42a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='553' max='475000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   553/475000 17:24 < 249:44:42, 0.53 it/s, Epoch 0.01/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fine_tuning.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc45068-1162-4e17-b6c3-878eb50080dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning.model.push_to_hub(PROJECT_RUN_NAME, private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql_expert",
   "language": "python",
   "name": "sql_expert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
